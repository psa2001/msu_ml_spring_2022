{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEalnZ4dHYrS"
      },
      "source": [
        "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
        "## Домашнее задание №4 - Градиентный бустинг\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97y2TRnyHYra"
      },
      "source": [
        "**Общая информация**\n",
        "\n",
        "**Срок сдачи:** 13 июня 2022, 08:30   \n",
        "**Штраф за опоздание:** -2 балла после 08:30 13 июня, -4 балла после 08:30 20 июня, -6 баллов после 08:30 24 мая, -8 баллов после 08:30 31 мая.\n",
        "\n",
        "При отправлении ДЗ указывайте фамилию в названии файла Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
        "[ML0422, Задание 4] Фамилия Имя. \n",
        "\n",
        "\n",
        "Используйте данный Ipython Notebook при оформлении домашнего задания."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXl2uzt9HYrb"
      },
      "source": [
        "##  Считаем производные для функций потерь (1 балл)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUSFk6pVHYrc"
      },
      "source": [
        "Мы будем реализовать градиентный бустинг для 3 функций потерь:\n",
        "\n",
        "1) MSE  $L(a(x_i), y_i) = (y_i - a(x_i)) ^ 2$\n",
        "\n",
        "2) Экспоненциальная  $L(a(x_i), y_i) = exp( -a(x_i) y_i), y_i \\in \\{-1, 1\\}$\n",
        "\n",
        "3) Логистическая  $L(a(x_i), y_i) = \\log (1 + exp( -a(x_i) y_i)), y_i \\in \\{-1, 1\\}$\n",
        "\n",
        "где $a(x_i)$ предсказание бустинга на итом объекте. \n",
        "\n",
        "Для каждой функции потерь напишите таргет, на который будет настраиваться каждое дерево в бустинге. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIbCyFsfHYrd"
      },
      "source": [
        "Ваше решение тут\n",
        "\n",
        "1) MSE: $\\frac{\\partial L}{\\partial F} = -2 * (y_i - a(x_i))$\n",
        "\n",
        "MSE target $(x_i, 2 * (y_i - a(x_i)))$\n",
        "\n",
        "2) Exponential: $\\frac{\\partial L}{\\partial L} = - y_i * exp^{-a(x_i) * y_i}$\n",
        "\n",
        "Exponential target $(x_i, y_i * exp^{-a(x_i) * y_i})$\n",
        "\n",
        "3) Binominal deviance / Cross-entropy: $\\frac{\\partial L}{\\partial F} = \\frac{-y_i}{1 + exp ^ {a(x_i * y_i)}}$ \n",
        "\n",
        "Binominal deviance / Cross-entropy target $(x_i, \\frac{y_i}{1 + exp ^ {a(x_i * y_i)}})$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KRcTC4xHYre"
      },
      "source": [
        "##  Реализуем градиентный бустинг (3 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ8sOrE9HYrf"
      },
      "source": [
        "Реализуйте класс градиентного бустинга для классификации. Ваша реализация бустинга должна работать по точности не более чем на 5 процентов хуже чем GradientBoostingClassifier из sklearn. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dza9J9TOHYrg"
      },
      "source": [
        "Детали реализации:\n",
        "\n",
        "-- должно поддерживаться 3 функции потерь\n",
        "\n",
        "-- сами базовые алгоритмы(деревья, линейные модели и тп) реализовать не надо, просто возьмите готовые из sklearn\n",
        "\n",
        "-- в качестве функции потерь для построения одного дерева используйте MSE\n",
        "\n",
        "-- шаг в бустинге можно не подбирать, можно брать константный\n",
        "\n",
        "-- можно брать разные модели в качестве инициализации бустинга\n",
        "\n",
        "-- должны поддерживаться следующие параметры:\n",
        "\n",
        "а) число итераций\n",
        "б) размер шага\n",
        "в) процент случайных фичей при построении одного дерева\n",
        "д) процент случайных объектов при построении одного дерева\n",
        "е) параметры базового алгоритма (передавайте через **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "2GPvs2kmHYrh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, RandomForestRegressor \n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 15\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "1puMQFB42kl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "UUL5n_HiHYrk"
      },
      "outputs": [],
      "source": [
        "class MyGradientBoostingClassifier:\n",
        "\n",
        "    def __init__(self, loss='MSE', learning_rate=1e-1, n_estimators=100, colsample=1., subsample=1., random_state=15, *args, **kwargs):\n",
        "        \"\"\"\n",
        "        loss -- один из 3 лоссов:\n",
        "        learning_rate -- шаг бустинга\n",
        "        n_estimators -- число итераций\n",
        "        colsample -- процент рандомных признаков при обучнеии одного алгоритма\n",
        "        colsample -- процент рандомных объектов при обучнеии одного алгоритма\n",
        "        args, kwargs -- параметры  базовых моделей\n",
        "        \"\"\"\n",
        "        self.loss = loss\n",
        "        self.learning_rate = learning_rate\n",
        "        self.n_estimators = n_estimators\n",
        "        self.colsample = colsample\n",
        "        self.subsample = subsample\n",
        "        self.args = args\n",
        "        self.kwargs = kwargs\n",
        "        self.model_ensemble = []\n",
        "        self.feature_idx = []\n",
        "        self.random_state=random_state\n",
        "        pass\n",
        "    \n",
        "    def losses_target_definition(self):\n",
        "        if(self.loss == 'MSE'):\n",
        "            return lambda a, y: 2 * (y - a)\n",
        "        elif(self.loss == 'Exponential'):\n",
        "            return lambda a, y: y * np.exp(-a * y)\n",
        "        elif(self.loss == 'Deviance'):\n",
        "            return lambda a, y: y / (1 + np.exp(a * y))\n",
        "\n",
        "    def modify_data(self, Y, to_train = 1):\n",
        "        if(np.unique(Y) == np.array([0, 1])):\n",
        "            if(to_train):\n",
        "                return (Y - 0.5) * 2\n",
        "            else:\n",
        "                return (Y + 1) // 2\n",
        "\n",
        "    def fit(self, X, y_orig, base_model=DecisionTreeRegressor, init_model=None):\n",
        "        \"\"\"\n",
        "        X -- объекты для обучения:\n",
        "        y -- таргеты для обучения\n",
        "        base_model -- класс базовых моделей, например sklearn.tree.DecisionTreeRegressor\n",
        "        init_model -- класс для первой модели, если None то берем константу (только для посл задания)\n",
        "        \"\"\"\n",
        "        self.base_model = base_model\n",
        "        self.init_model = init_model\n",
        "        self.target_func = self.losses_target_definition()\n",
        "        self.bin_task = False\n",
        "        y = copy.deepcopy(y_orig)\n",
        "        if(len(np.unique(y)) == 2):\n",
        "            self.bin_task = True\n",
        "            idx_0 = np.where(y == 0)\n",
        "            y[idx_0] = -1\n",
        "            idx_1 = np.where(y == 1)\n",
        "            idx_1 = 1\n",
        "\n",
        "        if(init_model is None):\n",
        "            f = np.zeros(X.shape[0])\n",
        "        else:\n",
        "            init_model_clf = init_model()\n",
        "            init_model_clf.fit(X, y)\n",
        "            f = init_model_clf.predict(X)\n",
        "        for i in range(self.n_estimators):\n",
        "            cur_sample_idx = np.random.choice(np.arange(X.shape[0]), size=round(X.shape[0] * self.colsample), replace=False)\n",
        "            cur_feature_idx = np.random.choice(np.arange(X.shape[1]), size=round(X.shape[1] * self.subsample), replace=False)\n",
        "            self.feature_idx.append(cur_feature_idx)\n",
        "            X_cur = X[np.ix_(cur_sample_idx, cur_feature_idx)]\n",
        "            Y_modified_cur = y[cur_sample_idx]\n",
        "            Y_antigrad = self.target_func(f[cur_sample_idx], Y_modified_cur)\n",
        "            cur_model = self.base_model(*self.args, **self.kwargs, random_state=self.random_state)\n",
        "            cur_model.fit(X_cur, Y_antigrad)\n",
        "            f[cur_sample_idx] += self.learning_rate * cur_model.predict(X_cur)\n",
        "            self.model_ensemble.append(cur_model)\n",
        "        pass\n",
        "        \n",
        "    def predict(self, X):\n",
        "        if(self.init_model is None):\n",
        "            f0 = np.zeros(X.shape[0])\n",
        "        else:\n",
        "            f0 = np.asarray(self.init_model.predict(X))\n",
        "        f =  np.zeros(X.shape[0])\n",
        "        for i in range(self.n_estimators):\n",
        "            f += self.model_ensemble[i].predict(X[:, self.feature_idx[i]])\n",
        "        f *= self.learning_rate\n",
        "        f += f0\n",
        "        f = f.round()\n",
        "        if(self.bin_task):\n",
        "            f[f >= 0] = 1\n",
        "            f[f < 0] = 0\n",
        "        return f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yngAFlbHYrl"
      },
      "outputs": [],
      "source": [
        "my_clf = MyGradientBoostingClassifier(random_state=SEED)\n",
        "clf = GradientBoostingClassifier(random_state=SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "hWP2pmNaHYrm"
      },
      "outputs": [],
      "source": [
        "wine = load_wine()\n",
        "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target, random_state=SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mG2MWTnHYrm",
        "outputId": "ea4b6f6e-7cb2-4dee-bf14-c88c423c1891"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8888888888888888\n",
            "0.8888888888888888\n"
          ]
        }
      ],
      "source": [
        "my_clf.fit(X_train, y_train)\n",
        "clf.fit(X_train, y_train)\n",
        "print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
        "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmcDzTCRHYrn"
      },
      "source": [
        "## Подбираем параметры (2 балла)\n",
        "\n",
        "Давайте попробуем применить Ваш бустинг для предсказаний цены домов в Калифорнии. Чтобы можно было попробовтаь разные функции потерь, переведем по порогу таргет в 2 класса: дорогие и дешевые дома."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQasCUdPHYro"
      },
      "source": [
        "В задании нужно\n",
        "\n",
        "1) Построить график точности в зависимости от числа итераций на валидации.\n",
        "\n",
        "2) Подобрать оптимальные параметры Вашего бустинга на валидации. \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.datasets import fetch_california_housing\n"
      ],
      "metadata": {
        "id": "bDBl40_UExlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_res(y):\n",
        "    return (y > 2.0).astype(int)"
      ],
      "metadata": {
        "id": "EnHNdVkJJgeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siozslhOHYro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cd44fac-1530-47c5-da7f-d441fc301495"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20640, 8) (20640,)\n"
          ]
        }
      ],
      "source": [
        "X, y = fetch_california_housing(return_X_y=True)\n",
        "# Превращаем регрессию в классификацию\n",
        "y = process_res(y)\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opti_params = {\n",
        "        'MSE': {\n",
        "            \"n_estimators\": 4,\n",
        "            \"learning_rate\": 1e-1,\n",
        "            \"subsample\": 1.0,\n",
        "            \"colsample\": 1.0,\n",
        "        },\n",
        "        'Exponential' : {\n",
        "            \"n_estimators\": 4,\n",
        "            \"learning_rate\": 1e-1,\n",
        "            \"subsample\": 1.0,\n",
        "            \"colsample\": 1.0,\n",
        "        },\n",
        "        'Deviance': {\n",
        "            \"n_estimators\": 4,\n",
        "            \"learning_rate\": 1e-1,\n",
        "            \"subsample\": 1.0,\n",
        "            \"colsample\": 1.0,\n",
        "        },\n",
        "\n",
        "    }"
      ],
      "metadata": {
        "id": "_EZ1IPHUcegP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validation_score(my_clf, X, y, random_state=3, num_split=4, base_model=DecisionTreeRegressor, *args, **kwargs):\n",
        "    skf = StratifiedKFold(n_splits=num_split, shuffle=True, random_state=random_state)\n",
        "    scores = []\n",
        "    for train_index, test_index in tqdm(skf.split(X, y)):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "        my_clf.fit(X_train, y_train,base_model=base_model)\n",
        "        y_predictions = my_clf.predict(X_test)\n",
        "        cur_score = accuracy_score(y_pred=y_predictions, y_true=y_test)\n",
        "        scores.append(cur_score)\n",
        "    return sum(scores) / len(scores)"
      ],
      "metadata": {
        "id": "c1xDBMXyEFCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "CJd4I-HXHYrr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88557839-6f35-45cd-aa1a-4e108b041a81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4it [00:11,  2.84s/it]\n",
            "4it [00:21,  5.46s/it]\n",
            "4it [00:36,  9.17s/it]\n",
            "4it [00:43, 10.91s/it]\n",
            "4it [00:45, 11.29s/it]\n",
            "4it [00:45, 11.41s/it]\n",
            "4it [00:45, 11.47s/it]\n",
            "4it [00:12,  3.01s/it]\n",
            "4it [00:23,  5.82s/it]\n",
            "4it [00:34,  8.56s/it]\n",
            "4it [00:44, 11.25s/it]\n",
            "4it [00:56, 14.09s/it]\n",
            "4it [01:06, 16.58s/it]\n",
            "4it [01:16, 19.24s/it]\n",
            "4it [00:11,  2.85s/it]\n",
            "4it [00:22,  5.71s/it]\n",
            "4it [00:33,  8.45s/it]\n",
            "4it [00:44, 11.17s/it]\n",
            "4it [00:56, 14.06s/it]\n",
            "4it [01:06, 16.62s/it]\n",
            "4it [01:16, 19.23s/it]\n"
          ]
        }
      ],
      "source": [
        "scores_history = {\n",
        "    'MSE': [],\n",
        "    'Exponential' : [],\n",
        "    'Deviance': []\n",
        "}\n",
        "\n",
        "number_of_estimators = np.arange(20, 160, 20)\n",
        "num_split = 4\n",
        "for cur_loss in scores_history:\n",
        "    for cur_num_estimators in number_of_estimators:\n",
        "        my_clf = MyGradientBoostingClassifier(random_state=SEED, n_estimators=cur_num_estimators, loss=cur_loss)\n",
        "        cur_score = validation_score(my_clf=my_clf, X=X, y=y, random_state=SEED, num_split=num_split)\n",
        "        scores_history[cur_loss].append(cur_score)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "fig=plt.figure()\n",
        "fig.show()\n",
        "ax=fig.add_subplot(111)\n",
        "\n",
        "ax.plot(number_of_estimators, scores_history['MSE'], color='b',label='MSE')\n",
        "ax.plot(number_of_estimators, scores_history['Exponential'], color='k', label='Exponential')\n",
        "ax.plot(number_of_estimators, scores_history['Deviance'], color='m', label='Deviance')\n",
        "\n",
        "plt.legend(loc=2)\n",
        "plt.draw()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "WUb8AEggIZos",
        "outputId": "8b40adba-9411-4f2a-f50b-efce3c3f2ffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for cur_loss in opti_params.keys():\n",
        "    max_val = max(scores_history[cur_loss])\n",
        "    idx_max = np.argmax(np.array(scores_history[cur_loss]))\n",
        "    best_param_val = number_of_estimators[idx_max]\n",
        "    opti_params[cur_loss]['n_estimators'] = best_param_val\n",
        "    print('loss - {0}, parameters - {1}: score: {2}'.format(cur_loss, opti_params[cur_loss], max_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtFUW9Y7cbIT",
        "outputId": "d8bdc477-73b4-441e-c08a-107a333817e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss - MSE, parameters - {'n_estimators': 100, 'learning_rate': 0.1, 'subsample': 1.0, 'colsample': 1.0}: score: 0.9573643410852714\n",
            "loss - Exponential, parameters - {'n_estimators': 100, 'learning_rate': 0.1, 'subsample': 1.0, 'colsample': 1.0}: score: 0.9575581395348838\n",
            "loss - Deviance, parameters - {'n_estimators': 140, 'learning_rate': 0.1, 'subsample': 1.0, 'colsample': 1.0}: score: 0.9577519379844961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "В качестве гиперпараметров подбираются:\n",
        "- learning rate\n",
        "- colsample\n",
        "- subsample\n",
        "Рассматриваются все вариации с loss-ми\n",
        "Гиперпараметер number_of_estimators уже подобран для разных конфигураций с loss-ми\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "syJSsBnKIZx8",
        "outputId": "807037b5-a805-4632-9fa1-13857b7d8449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nВ качестве гиперпараметров подбираются:\\n- learning rate\\n- colsample\\n- subsample\\nРассматриваются все вариации с loss-ми\\nГиперпараметер number_of_estimators уже подобран для разных конфигураций с loss-ми\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def grid_search(opti_parameter, optimization_grid, opti_params, X, y, random_state=3):\n",
        "\n",
        "    scores_history = {\n",
        "        'MSE': [],\n",
        "        'Exponential' : [],\n",
        "        'Deviance': []\n",
        "    }\n",
        "\n",
        "    for cur_loss in opti_params.keys():\n",
        "        for cur_opt_parameter in optimization_grid:\n",
        "            opti_params[cur_loss][opti_parameter] = cur_opt_parameter\n",
        "            my_clf = MyGradientBoostingClassifier(random_state=SEED, \n",
        "                                                  n_estimators=opti_params[cur_loss]['n_estimators'],\n",
        "                                                  learning_rate=opti_params[cur_loss]['learning_rate'],\n",
        "                                                  subsample=opti_params[cur_loss]['subsample'],\n",
        "                                                  colsample=opti_params[cur_loss]['colsample'])\n",
        "            cur_score = validation_score(my_clf=my_clf, X=X, y=y, random_state=random_state)\n",
        "            scores_history[cur_loss].append(cur_score)\n",
        "\n",
        "    return scores_history"
      ],
      "metadata": {
        "id": "AWToyZWlKyl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cur_opti_parameter = 'learning_rate'\n",
        "optimization_grid = np.linspace(1e-4, 1., num=20)\n",
        "lr_history = grid_search(opti_parameter=cur_opti_parameter, optimization_grid=optimization_grid, opti_params=opti_params, X=X, y=y, random_state=SEED)\n",
        "for cur_loss in opti_params.keys():\n",
        "    max_val = max(lr_history[cur_loss])\n",
        "    idx_max = np.argmax(np.array(lr_history[cur_loss]))\n",
        "    best_lr = optimization_grid[idx_max]\n",
        "    opti_params[cur_loss][cur_opti_parameter] = best_lr\n",
        "    print('loss - {0}, parameters - {1}: score: {2}'.format(cur_loss, opti_params[cur_loss], max_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-iV-d8HPDkv",
        "outputId": "8baff9a9-8dd2-4d33-a023-6697798399da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4it [01:01, 15.34s/it]\n",
            "4it [00:53, 13.46s/it]\n",
            "4it [00:43, 10.84s/it]\n",
            "4it [00:27,  6.90s/it]\n",
            "4it [00:19,  4.86s/it]\n",
            "4it [00:14,  3.64s/it]\n",
            "4it [00:11,  2.82s/it]\n",
            "4it [00:08,  2.23s/it]\n",
            "4it [00:07,  1.75s/it]\n",
            "4it [00:05,  1.26s/it]\n",
            "4it [00:05,  1.29s/it]\n",
            "4it [00:06,  1.75s/it]\n",
            "4it [00:08,  2.21s/it]\n",
            "4it [00:11,  2.83s/it]\n",
            "4it [00:14,  3.64s/it]\n",
            "4it [00:19,  4.94s/it]\n",
            "4it [00:27,  6.89s/it]\n",
            "4it [00:43, 10.82s/it]\n",
            "4it [00:53, 13.46s/it]\n",
            "4it [00:53, 13.39s/it]\n",
            "4it [01:01, 15.31s/it]\n",
            "4it [00:53, 13.49s/it]\n",
            "4it [00:42, 10.69s/it]\n",
            "4it [00:27,  6.84s/it]\n",
            "4it [00:19,  4.86s/it]\n",
            "4it [00:14,  3.64s/it]\n",
            "4it [00:11,  2.83s/it]\n",
            "4it [00:08,  2.22s/it]\n",
            "4it [00:06,  1.75s/it]\n",
            "4it [00:05,  1.26s/it]\n",
            "4it [00:05,  1.27s/it]\n",
            "4it [00:07,  1.76s/it]\n",
            "4it [00:09,  2.39s/it]\n",
            "4it [00:11,  2.83s/it]\n",
            "4it [00:14,  3.64s/it]\n",
            "4it [00:19,  4.89s/it]\n",
            "4it [00:27,  6.86s/it]\n",
            "4it [00:44, 11.23s/it]\n",
            "4it [00:53, 13.39s/it]\n",
            "4it [00:52, 13.21s/it]\n",
            "4it [01:26, 21.66s/it]\n",
            "4it [01:15, 18.77s/it]\n",
            "4it [00:43, 10.80s/it]\n",
            "4it [00:27,  6.98s/it]\n",
            "4it [00:20,  5.01s/it]\n",
            "4it [00:15,  3.78s/it]\n",
            "4it [00:11,  2.97s/it]\n",
            "4it [00:09,  2.36s/it]\n",
            "4it [00:07,  1.88s/it]\n",
            "4it [00:05,  1.39s/it]\n",
            "4it [00:05,  1.40s/it]\n",
            "4it [00:07,  1.88s/it]\n",
            "4it [00:09,  2.33s/it]\n",
            "4it [00:11,  2.97s/it]\n",
            "4it [00:15,  3.80s/it]\n",
            "4it [00:20,  5.21s/it]\n",
            "4it [00:28,  7.00s/it]\n",
            "4it [00:43, 10.95s/it]\n",
            "4it [01:14, 18.68s/it]\n",
            "4it [01:14, 18.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss - MSE, parameters - {'n_estimators': 100, 'learning_rate': 0.2632315789473684, 'subsample': 1.0, 'colsample': 1.0}: score: 0.9582364341085271\n",
            "loss - Exponential, parameters - {'n_estimators': 100, 'learning_rate': 0.4737368421052632, 'subsample': 1.0, 'colsample': 1.0}: score: 0.9579941860465117\n",
            "loss - Deviance, parameters - {'n_estimators': 140, 'learning_rate': 0.5263631578947369, 'subsample': 1.0, 'colsample': 1.0}: score: 0.958139534883721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cur_opti_parameter = 'subsample'\n",
        "optimization_grid = np.linspace(0.5, 1., num=20)\n",
        "subsample_history = grid_search(opti_parameter=cur_opti_parameter, optimization_grid=optimization_grid, opti_params=opti_params, X=X, y=y, random_state=SEED)\n",
        "for cur_loss in opti_params.keys():\n",
        "    max_val = max(lr_history[cur_loss])\n",
        "    idx_max = np.argmax(np.array(subsample_history[cur_loss]))\n",
        "    best_param_val = optimization_grid[idx_max]\n",
        "    opti_params[cur_loss][cur_opti_parameter] = best_param_val\n",
        "    print('loss - {0}, parameters - {1}: score: {2}'.format(cur_loss, opti_params[cur_loss], max_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pWah_F1IZ7D",
        "outputId": "aeea21fc-6d7d-4628-afc7-c93978b57346"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4it [00:08,  2.01s/it]\n",
            "4it [00:08,  2.03s/it]\n",
            "4it [00:07,  1.96s/it]\n",
            "4it [00:09,  2.38s/it]\n",
            "4it [00:09,  2.37s/it]\n",
            "4it [00:09,  2.35s/it]\n",
            "4it [00:09,  2.37s/it]\n",
            "4it [00:09,  2.41s/it]\n",
            "4it [00:11,  2.97s/it]\n",
            "4it [00:11,  2.79s/it]\n",
            "4it [00:11,  2.77s/it]\n",
            "4it [00:11,  2.77s/it]\n",
            "4it [00:12,  3.22s/it]\n",
            "4it [00:12,  3.23s/it]\n",
            "4it [00:12,  3.17s/it]\n",
            "4it [00:12,  3.20s/it]\n",
            "4it [00:12,  3.21s/it]\n",
            "4it [00:14,  3.65s/it]\n",
            "4it [00:14,  3.65s/it]\n",
            "4it [00:14,  3.65s/it]\n",
            "4it [00:03,  1.31it/s]\n",
            "4it [00:03,  1.31it/s]\n",
            "4it [00:03,  1.33it/s]\n",
            "4it [00:03,  1.12it/s]\n",
            "4it [00:03,  1.14it/s]\n",
            "4it [00:03,  1.15it/s]\n",
            "4it [00:03,  1.14it/s]\n",
            "4it [00:03,  1.14it/s]\n",
            "4it [00:03,  1.01it/s]\n",
            "4it [00:03,  1.02it/s]\n",
            "4it [00:03,  1.02it/s]\n",
            "4it [00:03,  1.00it/s]\n",
            "4it [00:04,  1.12s/it]\n",
            "4it [00:04,  1.12s/it]\n",
            "4it [00:04,  1.13s/it]\n",
            "4it [00:04,  1.14s/it]\n",
            "4it [00:04,  1.14s/it]\n",
            "4it [00:05,  1.27s/it]\n",
            "4it [00:05,  1.29s/it]\n",
            "4it [00:05,  1.27s/it]\n",
            "4it [00:03,  1.17it/s]\n",
            "4it [00:03,  1.14it/s]\n",
            "4it [00:03,  1.15it/s]\n",
            "4it [00:04,  1.01s/it]\n",
            "4it [00:04,  1.01s/it]\n",
            "4it [00:03,  1.00it/s]\n",
            "4it [00:03,  1.02it/s]\n",
            "4it [00:03,  1.02it/s]\n",
            "4it [00:04,  1.13s/it]\n",
            "4it [00:04,  1.17s/it]\n",
            "4it [00:04,  1.14s/it]\n",
            "4it [00:04,  1.16s/it]\n",
            "4it [00:05,  1.28s/it]\n",
            "4it [00:05,  1.27s/it]\n",
            "4it [00:05,  1.29s/it]\n",
            "4it [00:05,  1.28s/it]\n",
            "4it [00:05,  1.29s/it]\n",
            "4it [00:06,  1.62s/it]\n",
            "4it [00:05,  1.42s/it]\n",
            "4it [00:05,  1.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss - MSE, parameters - {'n_estimators': 100, 'learning_rate': 0.2632315789473684, 'subsample': 0.5263157894736842, 'colsample': 1.0}: score: 0.9582364341085271\n",
            "loss - Exponential, parameters - {'n_estimators': 100, 'learning_rate': 0.4737368421052632, 'subsample': 0.7894736842105263, 'colsample': 1.0}: score: 0.9579941860465117\n",
            "loss - Deviance, parameters - {'n_estimators': 140, 'learning_rate': 0.5263631578947369, 'subsample': 0.8421052631578947, 'colsample': 1.0}: score: 0.958139534883721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cur_opti_parameter = 'colsample'\n",
        "optimization_grid = np.linspace(0.5, 1., num=20)\n",
        "colsample_history = grid_search(opti_parameter=cur_opti_parameter, optimization_grid=optimization_grid, opti_params=opti_params, X=X, y=y, random_state=SEED)\n",
        "for cur_loss in opti_params.keys():\n",
        "    max_val = max(lr_history[cur_loss])\n",
        "    idx_max = np.argmax(np.array(colsample_history[cur_loss]))\n",
        "    best_param_val = optimization_grid[idx_max]\n",
        "    opti_params[cur_loss][cur_opti_parameter] = best_param_val\n",
        "    print('loss - {0}, parameters - {1}: score: {2}'.format(cur_loss, opti_params[cur_loss], max_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dnMUK48U2Nv",
        "outputId": "1fa3cc1e-cf82-4e16-92a6-b99465322fd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4it [00:14,  3.52s/it]\n",
            "4it [00:13,  3.45s/it]\n",
            "4it [00:14,  3.55s/it]\n",
            "4it [00:13,  3.44s/it]\n",
            "4it [00:13,  3.43s/it]\n",
            "4it [00:13,  3.35s/it]\n",
            "4it [00:13,  3.40s/it]\n",
            "4it [00:13,  3.36s/it]\n",
            "4it [00:13,  3.34s/it]\n",
            "4it [00:13,  3.30s/it]\n",
            "4it [00:12,  3.23s/it]\n",
            "4it [00:12,  3.21s/it]\n",
            "4it [00:12,  3.11s/it]\n",
            "4it [00:12,  3.12s/it]\n",
            "4it [00:12,  3.02s/it]\n",
            "4it [00:11,  2.90s/it]\n",
            "4it [00:11,  2.87s/it]\n",
            "4it [00:10,  2.69s/it]\n",
            "4it [00:10,  2.56s/it]\n",
            "4it [00:08,  2.02s/it]\n",
            "4it [00:08,  2.11s/it]\n",
            "4it [00:08,  2.13s/it]\n",
            "4it [00:08,  2.10s/it]\n",
            "4it [00:08,  2.11s/it]\n",
            "4it [00:09,  2.30s/it]\n",
            "4it [00:08,  2.09s/it]\n",
            "4it [00:08,  2.09s/it]\n",
            "4it [00:08,  2.06s/it]\n",
            "4it [00:08,  2.05s/it]\n",
            "4it [00:08,  2.06s/it]\n",
            "4it [00:07,  1.97s/it]\n",
            "4it [00:07,  1.97s/it]\n",
            "4it [00:07,  1.92s/it]\n",
            "4it [00:07,  1.93s/it]\n",
            "4it [00:07,  1.87s/it]\n",
            "4it [00:07,  1.82s/it]\n",
            "4it [00:06,  1.72s/it]\n",
            "4it [00:06,  1.61s/it]\n",
            "4it [00:05,  1.41s/it]\n",
            "4it [00:04,  1.01s/it]\n",
            "4it [00:10,  2.70s/it]\n",
            "4it [00:11,  2.79s/it]\n",
            "4it [00:10,  2.67s/it]\n",
            "4it [00:10,  2.68s/it]\n",
            "4it [00:10,  2.67s/it]\n",
            "4it [00:10,  2.72s/it]\n",
            "4it [00:10,  2.65s/it]\n",
            "4it [00:10,  2.67s/it]\n",
            "4it [00:10,  2.65s/it]\n",
            "4it [00:10,  2.68s/it]\n",
            "4it [00:10,  2.58s/it]\n",
            "4it [00:10,  2.58s/it]\n",
            "4it [00:10,  2.51s/it]\n",
            "4it [00:09,  2.50s/it]\n",
            "4it [00:09,  2.48s/it]\n",
            "4it [00:10,  2.57s/it]\n",
            "4it [00:09,  2.34s/it]\n",
            "4it [00:09,  2.25s/it]\n",
            "4it [00:08,  2.07s/it]\n",
            "4it [00:05,  1.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss - MSE, parameters - {'n_estimators': 100, 'learning_rate': 0.2632315789473684, 'subsample': 0.5263157894736842, 'colsample': 0.8947368421052632}: score: 0.9582364341085271\n",
            "loss - Exponential, parameters - {'n_estimators': 100, 'learning_rate': 0.4737368421052632, 'subsample': 0.7894736842105263, 'colsample': 1.0}: score: 0.9579941860465117\n",
            "loss - Deviance, parameters - {'n_estimators': 140, 'learning_rate': 0.5263631578947369, 'subsample': 0.8421052631578947, 'colsample': 1.0}: score: 0.958139534883721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61cDbm_-HYrr"
      },
      "source": [
        "## BooBag BagBoo (1 балл)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrwBV-wrHYrr"
      },
      "source": [
        "Попробуем объединить бустинг и бэгинг. Давайте\n",
        "\n",
        "1) в качестве базовой модели брать не дерево решений, а случайный лес (из sklearn)\n",
        "\n",
        "2) обучать N бустингов на бустрапированной выборке, а затем предикт усреднять"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q835vZqpHYrs"
      },
      "source": [
        "Попробуйте обе этих стратегии на данных из прошлого задания. Получилось ли улучшить качество? Почему?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing"
      ],
      "metadata": {
        "id": "_0Y3lLAB1fN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_res(y):\n",
        "    return (y > 2.0).astype(int)"
      ],
      "metadata": {
        "id": "XKmOLi6TIePS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "X, y = fetch_california_housing(return_X_y=True)\n",
        "# Превращаем регрессию в классификацию\n",
        "y = process_res(y)\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGa-8ac3vSUS",
        "outputId": "1a772cb4-b35e-4891-b90b-52becbe87adf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20640, 8) (20640,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "jDLNQzDyHYrs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe9c3742-6ec4-4df5-b0a9-dbe7a6faa854"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "1it [03:18, 198.09s/it]\u001b[A\n",
            "2it [06:39, 200.08s/it]\u001b[A\n",
            "3it [10:00, 200.51s/it]\u001b[A\n",
            "4it [13:21, 200.48s/it]\n",
            " 33%|███▎      | 1/3 [13:21<26:43, 801.95s/it]\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "1it [03:16, 196.87s/it]\u001b[A\n",
            "2it [06:23, 190.94s/it]\u001b[A\n",
            "3it [09:32, 189.79s/it]\u001b[A\n",
            "4it [12:42, 190.58s/it]\n",
            " 67%|██████▋   | 2/3 [26:04<12:58, 778.64s/it]\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "1it [03:04, 184.51s/it]\u001b[A\n",
            "2it [06:09, 184.86s/it]\u001b[A\n",
            "3it [09:18, 186.75s/it]\u001b[A\n",
            "4it [12:24, 186.18s/it]\n",
            "100%|██████████| 3/3 [38:34<00:00, 771.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'MSE': [0.9649709302325582], 'Exponential': [0.9586240310077518], 'Deviance': [0.8644379844961241]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "scores_history = {\n",
        "    'MSE': [],\n",
        "    'Exponential' : [],\n",
        "    'Deviance': []\n",
        "}\n",
        "\n",
        "num_split = 4\n",
        "for cur_loss in tqdm(scores_history):\n",
        "    my_clf = MyGradientBoostingClassifier(random_state=SEED, loss=cur_loss, n_estimators=15)\n",
        "    cur_score = validation_score(my_clf=my_clf, X=X, y=y, random_state=SEED, num_split=num_split, base_model=RandomForestRegressor)\n",
        "    scores_history[cur_loss].append(cur_score)\n",
        "print(scores_history)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_history = {\n",
        "    'MSE': [],\n",
        "    'Exponential' : [],\n",
        "    'Deviance': []\n",
        "}\n",
        "\n",
        "num_models = 1\n",
        "num_split = 4\n",
        "\n",
        "for cur_loss in scores_history:\n",
        "    skf = StratifiedKFold(n_splits=num_split, shuffle=True, random_state=SEED)\n",
        "    scores = []\n",
        "\n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "        y_predictions = np.zeros((y_test.shape[0], num_models))\n",
        "        for i in range(num_models):\n",
        "            my_clf = MyGradientBoostingClassifier(random_state=SEED, loss=cur_loss)\n",
        "            \n",
        "            cur_idxs = np.random.choice(np.arange(X_train.shape[0]), round(X_train.shape[0]/num_models), replace=False)\n",
        "\n",
        "            X_train_cur = X_train[cur_idxs]\n",
        "            y_train_cur = y_train[cur_idxs]\n",
        "\n",
        "            my_clf.fit(X_train_cur, y_train_cur)\n",
        "            y_prediction_cur = my_clf.predict(X_test)\n",
        "            y_predictions[:, i] = y_prediction_cur\n",
        "        y_predictions_mod = np.apply_along_axis(np.bincount, 1, np.array(y_predictions, dtype=np.int64), minlength=len(np.unique(y)))\n",
        "        y_predictions_mod = np.apply_along_axis(np.argmax, 1, y_predictions_mod)\n",
        "        scores.append(accuracy_score(y_pred=y_predictions_mod, y_true=y_test))\n",
        "    scores_history[cur_loss] = np.array(scores).mean()\n",
        "scores_history"
      ],
      "metadata": {
        "id": "dX1Wp9wDaVkY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e65e263e-c577-42d6-ab19-4d4f210e9620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Deviance': 0.834156976744186,\n",
              " 'Exponential': 0.8338662790697674,\n",
              " 'MSE': 0.8315891472868218}"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JbBmBh2g3z9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Результат не стал лучше. В случае с RandomForest думаю, что необходимо настраивать параметры.\n",
        "В случае с усреднием результатов по бустингам. Изначально бустинг работает так, что variance не очень большой, а bias - да. Как я понимаю, при таком подходе могут быть проблемы с variance дополнительные.\n",
        "\n",
        "*Я сократил число алгоритмов с RandomForest до 15, так как иначе у меня вылетало*"
      ],
      "metadata": {
        "id": "9gDfzv7l301b"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys327CdoHYrt"
      },
      "source": [
        "## Умная инициализация (1 балл)\n",
        "\n",
        "Попробуйте брать в качестве инициализации бустинга не константу, а какой-то алгоритм и уже от его предикта стартовать итерации бустинга. Попробуйте разные модели из sklearn: линейные модели, рандом форест, svm..\n",
        "\n",
        "Получилось ли улучшить качество? Почему?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "chRZWhVlabyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "Z7jYa_kLHYrt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97d20235-6fbc-476c-d0e0-50fed4d0a70d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4it [00:45, 11.33s/it]\n",
            "4it [00:55, 13.96s/it]\n",
            "4it [00:55, 13.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'MSE': [0.9575581395348838], 'Exponential': [0.9571220930232558], 'Deviance': [0.9576065891472868]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "scores_history = {\n",
        "    'MSE': [],\n",
        "    'Exponential' : [],\n",
        "    'Deviance': []\n",
        "}\n",
        "\n",
        "num_split = 4\n",
        "for cur_loss in scores_history:\n",
        "    my_clf = MyGradientBoostingClassifier(random_state=SEED, loss=cur_loss)\n",
        "    cur_score = validation_score(my_clf=my_clf, X=X, y=y, random_state=SEED, num_split=num_split, init_model=SVR, process_res=process_res)\n",
        "    scores_history[cur_loss].append(cur_score)\n",
        "print(scores_history)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores_history = {\n",
        "    'MSE': [],\n",
        "    'Exponential' : [],\n",
        "    'Deviance': []\n",
        "}\n",
        "\n",
        "num_split = 4\n",
        "for cur_loss in scores_history:\n",
        "    my_clf = MyGradientBoostingClassifier(random_state=SEED, loss=cur_loss)\n",
        "    cur_score = validation_score(my_clf=my_clf, X=X, y=y, random_state=SEED, num_split=num_split, init_model=SVR)\n",
        "    scores_history[cur_loss].append(cur_score)\n",
        "print(scores_history)"
      ],
      "metadata": {
        "id": "H5Qa_5CCbuNE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f284fc13-0f48-483f-f226-53c5f681cfe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4it [00:48, 12.21s/it]\n",
            "4it [00:56, 14.22s/it]\n",
            "4it [00:56, 14.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'MSE': [0.9568798449612403], 'Exponential': [0.9574127906976744], 'Deviance': [0.9576065891472868]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "3r7Ipm96HYrt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a54aed74-8a16-4c0c-a416-ad441acd985b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4it [00:45, 11.47s/it]\n",
            "4it [00:56, 14.08s/it]\n",
            "4it [00:55, 13.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'MSE': [0.9571705426356589], 'Exponential': [0.9573158914728682], 'Deviance': [0.9571705426356589]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "scores_history = {\n",
        "    'MSE': [],\n",
        "    'Exponential' : [],\n",
        "    'Deviance': []\n",
        "}\n",
        "\n",
        "num_split = 4\n",
        "for cur_loss in scores_history:\n",
        "    my_clf = MyGradientBoostingClassifier(random_state=SEED, loss=cur_loss)\n",
        "    cur_score = validation_score(my_clf=my_clf, X=X, y=y, random_state=SEED, num_split=num_split, init_model=LinearRegression)\n",
        "    scores_history[cur_loss].append(cur_score)\n",
        "print(scores_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Результат не стал лучше. Думаю, что необходимо настраивать init_model."
      ],
      "metadata": {
        "id": "iYfanovH3XGk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAznKiBQHYrt"
      },
      "source": [
        "## Фидбек (бесценно)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ8Udj7LHYru"
      },
      "source": [
        "* Какие аспекты обучения  ансамблей Вам показались непонятными? Какое место стоит дополнительно объяснить?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KECxA3zKHYru"
      },
      "source": [
        "### Ваш ответ здесь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JK-8qk7HYru"
      },
      "source": [
        "* Здесь Вы можете оставить отзыв о этой домашней работе или о всем курсе."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kf7Y2J4QHYru"
      },
      "source": [
        "### ВАШ ОТЗЫВ ЗДЕСЬ\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "1d7t1X1qHYru"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "da9jrC8kHYru"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Pyatkovskiy_gradient_boosting_hw4.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "61cDbm_-HYrr",
        "ys327CdoHYrt",
        "oAznKiBQHYrt"
      ]
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}